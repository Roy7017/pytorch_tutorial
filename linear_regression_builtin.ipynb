{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Follows YouTube PyTorch tutorial at <https://www.youtube.com/watch?v=GIsg-ZUy0MY>. Around timestamp 1:10:00"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear regression using PyTorch built-ins"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Inputs: Temp, rainfall, humidity\r\n",
    "inputs = np.array([[73, 67, 43],\r\n",
    "                    [91, 88, 64],\r\n",
    "                    [87, 134, 58],\r\n",
    "                    [102, 43, 37],\r\n",
    "                    [69, 96, 70]], dtype='float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Targets: apples, oranges\r\n",
    "targets = np.array([[56, 70],\r\n",
    "                    [81, 101],\r\n",
    "                    [119, 133],\r\n",
    "                    [22, 37],\r\n",
    "                    [103, 119]], dtype='float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "inputs = torch.from_numpy(inputs)\r\n",
    "targets = torch.from_numpy(targets)\r\n",
    "inputs, targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 69.,  96.,  70.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset and DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `TensorDataset` allows access to `inputs` and `targets` as tuples and provides standard APIs for working with many different types of datasets in PyTorch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from torch.utils.data import TensorDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Define dataset\r\n",
    "train_ds = TensorDataset(inputs, targets)\r\n",
    "train_ds[0:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `TensorDataset` allows us to access a small section of the training data using the array indexing notation. It returns a tuple in which the first element contains the input variables for the selected rows and the second contains the targets.\r\n",
    "\r\n",
    "We'll also create a DataLoader, which can split data into branches of a predefined size while training. It also provides other utilities like shuffling and random sampling of data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Define data loader\r\n",
    "batch_size = 5\r\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What `shuffle=True` means is before creating the batches it shuffles the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `DataLoader` is typically used in a `for` loop."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "for xb, yb in train_dl:\r\n",
    "    print(xb, yb)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.]]) tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [ 22.,  37.],\n",
      "        [119., 133.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# nn.Linear\r\n",
    "\r\n",
    "Instead of initializing the weights and biases manually, we can define the model using the `nn.Linear` class from PyTorch, which does it automatically."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Define model\r\n",
    "model = nn.Linear(3, 2)\r\n",
    "model.weight, model.bias"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2721, -0.0777, -0.0572],\n",
       "         [-0.3578, -0.2715,  0.0870]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0906, 0.1579], requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch models also have a helpful `.parameters()` method, which returns a list containing all the weights and biases matrices present in the model. For our linear regression model, we have on weight matrix and one bias matrix. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "list(model.parameters())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2721, -0.0777, -0.0572],\n",
       "         [-0.3578, -0.2715,  0.0870]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0906, 0.1579], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the model to generate predictions in the exact same way as before."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "preds = model(inputs)\r\n",
    "preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-27.4382, -40.4128],\n",
       "        [-35.1686, -50.7280],\n",
       "        [-37.3137, -62.3093],\n",
       "        [-33.1198, -44.7947],\n",
       "        [-30.1476, -44.5063]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss Function\r\n",
    "\r\n",
    "Instead of defining loss functions manually, we can use the built in loss-functions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `nn.functional` package contains many useful loss functions and several utilities."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Define loss functional \r\n",
    "loss_fn = F.mse_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "loss = loss_fn(model(inputs), targets)\r\n",
    "loss"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(17244.0293, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizer\r\n",
    "\r\n",
    "Instead of manually manipulating the model's parameters using gradients, we can use the optimizer `optim.SGD`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Define optimizer\r\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that `model.parameters()` is passed to the optimizer so that it knows which matrices should be modified during the update step. Also we specify the learning rate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\r\n",
    "\r\n",
    "We implement the same steps for gradient descent:\r\n",
    "\r\n",
    "1. Generate predictions.\r\n",
    "2. Calculate the loss.\r\n",
    "3. Compute the gradients w.r.t the weights and biases.\r\n",
    "4. Adjust the weights by substracting a small quality proportional to the gradient.\r\n",
    "5. Reset the gradients to Zero\r\n",
    "\r\n",
    "And we'll be working with batches of data instead of the whole data every iteration. we'll define a utility fit function which trains the model for a given number of epochs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def fit(num_epochs, model, loss_fn, opt):\r\n",
    "    # for each epoch, we run through our data\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        \r\n",
    "        # For each batch in our training data, we go through a gradient descent loop.\r\n",
    "        for  xb, yb in train_dl:\r\n",
    "            \r\n",
    "            # 1. Generate predictions\r\n",
    "            preds = model(xb)\r\n",
    "\r\n",
    "            # 2. Calculate the loss\r\n",
    "            loss = loss_fn(preds, yb)\r\n",
    "\r\n",
    "            # 3. Compute the gradients\r\n",
    "            loss.backward()\r\n",
    "\r\n",
    "            # 4. Update the paramters\r\n",
    "            opt.step()\r\n",
    "\r\n",
    "            # 5. Reset the gradients to zero\r\n",
    "            opt.zero_grad()\r\n",
    "\r\n",
    "        # Print the progress every 10 epochs\r\n",
    "        if (epoch + 1) % 10 == 0:\r\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some things to note:\r\n",
    "- We use the data loader defined above (Globally) \r\n",
    "- Instead updating the paramters manually, we use the optimizer (`opt.step()`) to perform the update and `opt.zero_grad()` to reset them to zero.\r\n",
    "- We added a log statement that shows the loss every 10 epochs. `loss.item()` returns the actual value stored in the loss tensor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train our model for 200 epochs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "fit(250, model, loss_fn, opt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [10/250], Loss: 805.4483032226562\n",
      "Epoch [20/250], Loss: 293.786376953125\n",
      "Epoch [30/250], Loss: 251.9359893798828\n",
      "Epoch [40/250], Loss: 222.95248413085938\n",
      "Epoch [50/250], Loss: 197.5584716796875\n",
      "Epoch [60/250], Loss: 175.17657470703125\n",
      "Epoch [70/250], Loss: 155.4447021484375\n",
      "Epoch [80/250], Loss: 138.0470428466797\n",
      "Epoch [90/250], Loss: 122.70530700683594\n",
      "Epoch [100/250], Loss: 109.17462158203125\n",
      "Epoch [110/250], Loss: 97.23921203613281\n",
      "Epoch [120/250], Loss: 86.70904541015625\n",
      "Epoch [130/250], Loss: 77.41676330566406\n",
      "Epoch [140/250], Loss: 69.2149887084961\n",
      "Epoch [150/250], Loss: 61.974021911621094\n",
      "Epoch [160/250], Loss: 55.579376220703125\n",
      "Epoch [170/250], Loss: 49.930458068847656\n",
      "Epoch [180/250], Loss: 44.938621520996094\n",
      "Epoch [190/250], Loss: 40.525760650634766\n",
      "Epoch [200/250], Loss: 36.62309265136719\n",
      "Epoch [210/250], Loss: 33.170021057128906\n",
      "Epoch [220/250], Loss: 30.11318016052246\n",
      "Epoch [230/250], Loss: 27.40557861328125\n",
      "Epoch [240/250], Loss: 25.00590705871582\n",
      "Epoch [250/250], Loss: 22.8775634765625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "preds = model(inputs)\r\n",
    "preds, targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 58.6420,  71.7206],\n",
       "         [ 81.1299,  99.6374],\n",
       "         [118.7685, 133.0384],\n",
       "         [ 29.3656,  44.8612],\n",
       "         [ 95.2309, 112.7947]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "93a6a9b76bfd63e02ab1b2bd2e6bc5ff501c9330c8c8db6caa76d3262061148d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}